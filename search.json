[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Is ChatGPT really that smart?\n\n\n\n\n\n\nLLMs\n\n\nChatGPT 4.0\n\n\nIQ\n\n\nLogic\n\n\n\nPerforming pattern recognition questions with ChatGPT 4.0\n\n\n\n\n\nMar 17, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nIs Claude a Gaúcho?\n\n\n\n\n\n\nLLMs\n\n\nClaude\n\n\nRegionalism\n\n\nGaúcho\n\n\n\nUnderstanding how LLMs perceive and process local slangs and linguistic regionalism\n\n\n\n\n\nMar 17, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2 - LLMs filters and security restrictions\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nLLama\n\n\nGoogle Gemini\n\n\n\nTesting inadequate prompts in Llama\n\n\n\n\n\nMar 2, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nPortuguese to English, English to Portuguese.\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nLLama\n\n\nGoogle Gemini\n\n\n\nComparing how ChatGPT’s answers vary according to prompts in different languages.\n\n\n\n\n\nMar 2, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nPart 1 - LLMs filters and security restrictions\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nfilter\n\n\nprompt hacking\n\n\n\nWhy doesn’t GPT provide you with answers to every single prompt?\n\n\n\n\n\nFeb 25, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nThe Symphony of Technology: Harmonizing AI with Human Creativity\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nprompt hacking\n\n\ncreativity\n\n\nweb scraping\n\n\n\nI Robot…\n\n\n\n\n\nFeb 25, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nNot enough data?\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nupdate\n\n\n3.5 vs 4.0\n\n\n\nHow ChatGPT 4 answers vary according to programming languages and their popularity.\n\n\n\n\n\nFeb 15, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\nOdds are not good if you are betting on ChatGPT\n\n\n\n\n\n\nLLMs\n\n\nSuper Bowl\n\n\nBets\n\n\nSecurity\n\n\n\nAn overview of ChatGPT unbiased view and security protocols\n\n\n\n\n\nFeb 10, 2024\n\n\nGabriel\n\n\n\n\n\n\n\n\n\n\n\n\n1 + 1 = 2 … perhaps not for Microsoft Copilot\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nCopilot\n\n\n\nA brief analysis of one of Microsoft Copilot weaknesses\n\n\n\n\n\nFeb 10, 2024\n\n\nGabriel\n\n\n\n\n\n\n\n\n\n\n\n\nChange in parameters and financial markets\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nupdate\n\n\n3.5 vs 4.0\n\n\n\nHow ChatGPT 4 recent update reflects on its answers to some prompts \n\n\n\n\n\nFeb 10, 2024\n\n\nGabriel Thiessen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/newvsold/index.html",
    "href": "posts/newvsold/index.html",
    "title": "Change in parameters and financial markets",
    "section": "",
    "text": "Prompt: Draw an image of ChatGPT 3.5 and 4.o fighting"
  },
  {
    "objectID": "posts/newvsold/index.html#how-do-llms-and-their-answers-change-with-time",
    "href": "posts/newvsold/index.html#how-do-llms-and-their-answers-change-with-time",
    "title": "Change in parameters and financial markets",
    "section": "How do LLMs and their answers change with time?",
    "text": "How do LLMs and their answers change with time?\nDuring one of my COMM 4190 class’ in-class activities, I came across a situation that raised this doubt in my head. The activity in particular was focused on making the LLM of your choice come up with an idea for a product, as well as its name and descritpion. Initially, I used ChatGPT 4 to provide me with some ideas of businesses that would be interesting and attractive for customers.\n\nThis is what ChatGPT 4 generated\n\n\nEco-Friendly Packaging Solutions: Develop a range of biodegradable and compostable packaging products for businesses in the food, beverage, and retail sectors, aiming to reduce plastic waste and carbon footprint.\n\n\nTelehealth Services for Mental Health: Create an online platform that provides accessible, affordable, and confidential mental health services, including therapy sessions, mental wellness tools, and community support, especially targeting remote areas with limited access to such services.\n\n\nSmart Home Integration Systems: Develop a comprehensive smart home system that seamlessly integrates various smart devices and appliances, offering enhanced convenience, energy efficiency, and security through a single, user-friendly interface.\n\n\nSubscription-Based Meal Prep Kits for Special Diets: Offer a subscription service that delivers weekly meal prep kits catering to specific dietary needs such as vegan, keto, gluten-free, etc., focusing on healthy, organic ingredients and sustainable packaging.\n\n\nAI-Powered Educational Tools for Personalized Learning: Create an AI-driven platform that offers personalized learning experiences for students, adapting to their learning pace, style, and interests, and providing real-time feedback to enhance their educational journey.\n\n\nVirtual Reality Experiences for Remote Tourism: Develop virtual reality packages that allow users to experience travel and cultural tours from the comfort of their homes, targeting travel enthusiasts unable to travel due to health, financial, or other constraints.\n\n\nRenewable Energy Solutions for Small Businesses: Offer consultancy and implementation services for small and medium-sized enterprises (SMEs) to transition to renewable energy sources, including solar, wind, and biomass, reducing their energy costs and environmental impact.\n\n\nWearable Health Monitoring Devices: Design and manufacture wearable devices that monitor vital health metrics in real-time, such as heart rate, blood pressure, and glucose levels, catering to individuals with chronic conditions or those seeking to maintain a healthy lifestyle.\n\n\nBlockchain-Based Supply Chain Management Platform: Create a blockchain platform that enhances transparency, efficiency, and security in supply chains, allowing businesses to track products from origin to consumer, reducing fraud, and ensuring ethical practices.\n\n\nSustainable Urban Farming Solutions: Develop innovative urban farming solutions, such as vertical farms or hydroponic systems, that enable city dwellers to grow fresh produce efficiently, promoting local food production and sustainability.\n\n\nSome nice business ideas, right? Now, this is what GPT 3.5 generated\n\n\nVirtual Event Management Platform: Develop a comprehensive platform that enables businesses and organizations to plan, manage, and host virtual events such as conferences, trade shows, and webinars. Offer features like customizable event spaces, attendee engagement tools, and analytics.\n\n\nEco-Friendly Packaging Solutions: Create a company that specializes in producing sustainable and biodegradable packaging materials for businesses looking to reduce their environmental footprint. Offer customizable solutions for various industries, including food and beverage, cosmetics, and e-commerce.\n\n\nRemote Work Productivity Tools: Develop software tools designed to enhance productivity and collaboration for remote teams. This could include project management platforms, communication tools, and virtual team-building solutions tailored to the needs of distributed workforces.\n\n\nPersonalized Health and Wellness Plans: Launch a service that provides personalized health and wellness plans based on individual needs, preferences, and goals. Offer features such as virtual consultations with nutritionists, fitness trainers, and wellness coaches, along with customized meal plans and exercise routines.\n\n\nRenewable Energy Consultancy: Start a consultancy firm specializing in renewable energy solutions for businesses and organizations seeking to transition to sustainable energy sources. Provide services such as energy audits, feasibility studies, and implementation strategies for solar, wind, and other renewable energy technologies.\n\n\nTech-Empowered Elderly Care Services: Create a business that leverages technology to provide innovative elderly care services, such as remote health monitoring systems, medication management apps, and virtual caregiver support networks. Focus on improving quality of life and promoting independence for seniors.\n\n\nSubscription Box for Sustainable Living: Curate and deliver subscription boxes filled with eco-friendly products and sustainable lifestyle items, such as organic skincare products, reusable household goods, and ethically sourced clothing. Offer monthly or quarterly subscription plans with customizable options.\n\n\nOnline Learning Platform for Skilled Trades: Develop an online learning platform that offers courses and certification programs for skilled trades such as plumbing, electrical work, carpentry, and HVAC repair. Provide high-quality instructional content, interactive simulations, and hands-on training modules.\n\n\nSmart Home Installation and Integration Services: Launch a company that specializes in installing and integrating smart home devices and systems, such as smart thermostats, security cameras, lighting controls, and home automation hubs. Offer consultation, installation, and maintenance services to homeowners and businesses.\n\n\nVirtual Interior Design Consultancy: Provide virtual interior design services for residential and commercial clients, offering personalized design consultations, mood boards, and 3D renderings. Utilize technology such as augmented reality (AR) to allow clients to visualize design concepts in their own spaces.\n\n\nOk, so what?\nOn a first look, it seems that both the answers are fundamentally the same. However, there is one specific subtlety that makes this whole comparison really interesting. If you take a closer look, it is possible to see that ChatGPT 3.5 mentions in some of his answers business ideas that are related to the use of virtual reality. However, there is no reference to AI-related businesses. Meanwhile, ChatGPT 4.0 included some of its business ideas AI-Powered Educational Tools for Personalized Learning. Even though it is a minor change, I truly believe that this is a really interesting way to analyze how updates on ChatGPT parameters reflect on their answers.\n\n\nRecent updates\nTo clarify my point, it is worth mentioning that the last update on ChatGPT 3.5 happened in January 2022 (reported by the AI tool itself). However, ChatGPT 4.0 includes data up to April 2023. Back in January 2022, AI was not a big topic when it came to business ideas, as we were still focusing on the Metaverse and blockchain. In between these two dates, though, we witnessed an abnormal growth in the use and popularity of AI tools for the most varied topics, ranging from education to business. Therefore, it is naturally reflected in the answers that this LLM provides. Pretty cool, right?\nThank you for reading!"
  },
  {
    "objectID": "posts/portuguese/index.html",
    "href": "posts/portuguese/index.html",
    "title": "Portuguese to English, English to Portuguese.",
    "section": "",
    "text": "Prompt: Generate an image of ChatGPT trying to speak Portuguese and English."
  },
  {
    "objectID": "posts/portuguese/index.html#is-chatgpt-polyglot-or-at-least-does-he-interpret-all-the-languages-the-same",
    "href": "posts/portuguese/index.html#is-chatgpt-polyglot-or-at-least-does-he-interpret-all-the-languages-the-same",
    "title": "Portuguese to English, English to Portuguese.",
    "section": "Is ChatGPT polyglot? Or at least, does he interpret all the languages the same?",
    "text": "Is ChatGPT polyglot? Or at least, does he interpret all the languages the same?\nAs a non-native English speaker, I often feel that my brain is just an inner turmoil of different languages: I read texts in English and listen to my professors lecturing in English but think in Portuguese, sometimes in English. Honestly, it is not easy, but I feel that I am gradually getting used to it and processing my thoughts mostly in English in a really natural and, from a logical and grammatical standpoint, correct way. I mean, when reading or listening to something in English, fundamentally no meaning or important information is lost in meanwhile I process such information. However, it took me years of learning the language to be able to do it so, and lots of help from the magical complexity of the human brain, and its capabilities such as as neuroplasticity and ability to make logical correlations and inferences in a matter of milliseconds.\nSo, after wondering about how I actually deal with thinking in two languages at the same time, I caught myself intrigued: is ChatGPT able to do it?\n\n“Of course ChatGPT can!”\nWell, yes, ChatGPT is for sure able to do it. In fact, if you ask ChatGPT what languages he can interpret, this is his answer.\n\nConsidering that ChatGPT is an LLM with approximately 175 billion parameters, it was quite expected that ChatGPT would be polyglot. But I really want to show with this article is to what extense. In this case, I will evaluate whether ChatGPT 4 can generate the same answer to equal prompts but in three different contexts: asking in English, asking in Portuguese, and writing a prompt in English but asking ChatGPT to answer it in Portuguese (additionally, I will check this different cases in distinct browser windows, to avoid ChatGPT to be based on previous prompts). Also, the question will be, “Can you explain to me what an LLM is?” Therefore, let’s go to prompting!\n\n\n“Can you explain to me what an LLM is?”\nFirstly, let’s analyze how ChatGPT answers this question in English.\n\nNow, let’s check how ChatGPT answers the question in Portuguese\n\nFinally, let’s see how ChatGPT performs when mixing the two languages.\n\nUmmm, interesting…\n\n\nConclusion\nWell, you don’t have to be a polyglot, be a communication wizard, or fluently speak both Portuguese and English to realize that, yes, its answers vary based on the prompt and the language that you used to make the prompt. In the case of pure English, ChatGPT seemed to provide a really straightforward and correct answer. Also, unlike the response in Portuguese, it goes on to briefly explain some of the technical concepts related to the field, as well as what the acronym stands for. Meanwhile, in Portuguese, ChatGPT seems to provide an answer that is way more developed, with bulletproofs, key concepts, and introductory, development, and conclusive parts to the answer. Still, in both cases ChatGPT generated answers that are quite similar, but slightly vary on the way they were presented and how concepts were explained, such as transformers and training. But, when it comes to the last case, which consisted of asking ChatGPT in English to provide an answer in Portuguese, then we it was possible to witness a major difference. Unlike the previous cases, this time, ChatGPT generate a way less technical explanation, barely went through the most important aspects of LLMs, and, just by visualizing the size of the answer, one can tell that it not even close to being as complete as the previous ones.\nIt is difficult, though, to understand why such a significant discrepancy occurred. Usually, when I ask ChatGPT to translate words from Portuguese to English, it does quite a good job. However, my guess to why this happens is that OpenAI is perhaps not really focused on training ChatGPT to intercalate languages in its prompts, as it something quite not “natural” to be asked. While the reason for this might still be a little uncertain, I believe that I can rest in knowing that my overwhelmed brain processing Portuguese and English is still a little bit ahead of ChatGPT information processing capacity. At least for now…\nThank you for reading!"
  },
  {
    "objectID": "posts/llama/index.html",
    "href": "posts/llama/index.html",
    "title": "Part 1 - LLMs filters and security restrictions",
    "section": "",
    "text": "Prompt: Draw an image of someone stopping ChatGPT from talking."
  },
  {
    "objectID": "posts/llama/index.html#restrictions-restrictions-and-restrictions",
    "href": "posts/llama/index.html#restrictions-restrictions-and-restrictions",
    "title": "Part 1 - LLMs filters and security restrictions",
    "section": "Restrictions, restrictions, and restrictions",
    "text": "Restrictions, restrictions, and restrictions\nHave you ever tried to find the correct formula to build a bomb at home? Have you ever tried to make ChatGPT imitate that one friend with a really suspicious sense of humor? Have you ever tried to make ChatGPT come up with a brilliant plan to hide criminal proof?\nNo? Great! Then it means that you are probably a good person and a law-abiding citizen (also if these are some of your usual prompts, and I think you should rethink some of your life choices). Either way, I will assume that you are a normal person who does not try to build bombs at home and, thus, never tried to get some response on ChatGPT on how to do it. To show you the outcome, this is what ChatGPT generates when I ask him to do such a thing.\n\nWell, as you can see and might as well have presumed, finding the “magical recipe” to develop the new atomic bomb from the comfort of your own home. But why is that? Shouldn’t LLMs just act like humans trying to communicate and develop logically correct sentences? Well, technically, yes. But imagine you are the CEO of a new OpenAI-like company that has developed the most advanced LLM. Would you like people to be able to use your technology to destroy the country and perform terrorist attacks? OF COURSE NOT. And this is the reason why tech companies invest millions and billions of dollars to limit this unwanted response."
  },
  {
    "objectID": "posts/counting_copilot/index.html",
    "href": "posts/counting_copilot/index.html",
    "title": "1 + 1 = 2 … perhaps not for Microsoft Copilot",
    "section": "",
    "text": "Prompt: Draw an image of ChatGPT counting letters in words."
  },
  {
    "objectID": "posts/counting_copilot/index.html#a-simple-counting-problem",
    "href": "posts/counting_copilot/index.html#a-simple-counting-problem",
    "title": "1 + 1 = 2 … perhaps not for Microsoft Copilot",
    "section": "A simple counting problem",
    "text": "A simple counting problem\n\nFor most people, counting numbers is a simple operation composed of basically adding numbers. From an early age, most of us know how to compute 1 + 1, 2 + 2, and 2 - 1. It is an intuitive operation that is ubiquitous in our daily lives. As LLMs are basically developed to generate responses that are most likely human ones, one would infer that LLMs do not have a problem in computing the total price of multiple objects, calculating means and medians, and counting the number of letters in a single word… However, this last one might not be so easy for them to figure out. To better understand what I am saying, let’s go through a sample question\n\nCount the number that each letter appears in the word college.\n\n\nYou will probably answer something like c = 1, o = 1, l = 2, e = 2, g = 1…\nAnd that’s it! There is no interpretation, no magical formula, no advanced counting theorem. Just pure and simple math. However, how do we really perform this operation?\n\nHow do we do it?\nSome people might deliberate a bit on these simple additions, especially people who might instantly respond to the questions. No matter if it is our automatic or analytical brain system (shoutout to Daniel Kahneman) that is performing the operation, one thing is for sure: it is a simple counting operation.\nWe basically identify different characters visually based on previous knowledge of the alphabet and its characters and perform logical steps composed of adding numbers to check how many times the characters with the same visual representation are represented in this specific range of letters. This ability to perform simple operations (which are not too simple for a machine) comes from our brain’s impressive capacity for interpreting, storing, and using visual data for other means. It is as simple as that: you look, interpret, and do whatever you want with this information without any additional step to evaluate such values. However, that is not how LLMs work.\nTo perform any type of operation, LLMs rely on a process called tokenization. Tokenization is one of the fundamental steps in data analysis for LLMs in which they process, usually words, as a set of integers. For instance, while we read “dog” as just “dog,” a machine interprets dogs as 001. This step is pivotal for generative AI, as it allows the machine to make associations of what words most often appear after the dog in a sentence and, thus, allows it to come up with a plausible answer.\nBut letters are a whole different story… You might be wondering, what if we want to analyze letters in a word? This tokenization process is then applied to each individual character in the designated word, which turns out to be troublesome for some specific LLMs. In the case of Copilot, no matter if it is a common word in terms of recurrence or an unusual word, it has difficulties in tokenizing it. Check it out below.\n\n\nHow does Copilot respond to the prompt?\nGPT3.5 Turbo\n\n\nAs you can see, it has a lot of difficulties processing the word anthropology.\n\nWhat about other words\n\n\nThis time, though, Copilot successfully counted the number of letters in the word college\n\nIs is the same thing for ChatGPT 4?\n\n\nUnlike what you may be thinking, not actually. Supposedly, Copilot uses Open AI’s GPT 4, too. However, when we insert the exact same prompt on ChatGPT 4, it answers correctly!\n\nWhat can we conclude with this experiment?\nI would say that the results obtained can show us two important things: LLMs are still, in general, not good at processing individual words, and ChatGPT 4 and Copilot are perhaps not as similar as we thought.\nRegarding the first assertion, doing this experience makes it really easy to visualize the limitations of performing tokenization in comparison to the way that the human brain interprets words and counting. Probably, for more unusual words, like anthropology, Copilot simply attributes the same tokens to different letters or computes syllables as single words. Meanwhile, for more usual words in the English language, like college, its word tokenization process is more optimized and thus does not generate any problem in terms of interpretation and computation.\nWHAT ABOUT ChatGPT 4?\nWell, that is content for other articles, but at least in theory, Copilot should behave similarly to ChatGPT 4. Perhaps this indicates that, in fact, ChatGPT 4 and Copilot are not as similar as Microsoft proposed…\nThank you for reading!"
  },
  {
    "objectID": "posts/superbowl/index.html",
    "href": "posts/superbowl/index.html",
    "title": "Odds are not good if you are betting on ChatGPT",
    "section": "",
    "text": "Prompt: Draw an image of Superbowl 2024"
  },
  {
    "objectID": "posts/superbowl/index.html#a-national-holiday",
    "href": "posts/superbowl/index.html#a-national-holiday",
    "title": "Odds are not good if you are betting on ChatGPT",
    "section": "A national holiday",
    "text": "A national holiday\n\nThis Sunday is a special date for most Americans who, like me, love football (in my case, the true one, a.k.a soccer for you citizens of the US): the Super Bowl. At 6:30 pm on February 11th, the Kansas City Chiefs and the San Francisco 49ers will compete for the title of the Super Bowl, perhaps the most sought-after title in every sport, in Las Vegas, a controversial place that raises the debate of something that has been disturbing the world of sports worldwide: betting.\nThe rise of online casinos and betting platforms has generated a massive increase in the number of individual gamblers who want to try their luck in whatever game they desire to bet on.\n\n\nWhat does it have to do with ChatGPT?\nI’m not going to lie, but for some people, betting on sports has nothing to do with ChatGPT. Nevertheless, while using this phenomenal LLM, a doubt came across my mind: what if I asked for gambling suggestions from ChatGPT? Do not blame; the thing is basically a super brain with almost unlimited access to data; its opinion must be valid.\nTherefore, I tried to ask ChatGPT 4.0 what team I should bet on for the Super Bowl. You can see the prompt below.\n  \n\n\nThe point that I was trying to bring up with all of this\n\nAfter reading GPT’s response, you probably had the same impressions as me: yep, it was a pretty standard response. Indeed, that is what I was actually expecting from the LLM, which was basically statistical data scrapped from the web with a touch of information as well. Overall, it is a satisfactory one. However, there is one thing for me that is truly interesting: there is not even a single word that indicates bias or a recommendation to pick a specific team. On the one hand, people might think that it was because ChatGPT is not able to conclude things logically. However, if you ask ChatGPT 4.0 complex Calculus II questions (as I have already done) it will have no problem in gathering the information processed/obtained and presenting a logical conclusion. However, despite of having the data that concluded the likelihood of both teams to win, it did not even indicate what team would be the best to bet on.\nAnd no, ChatGPT 4.0 is not getting “less intelligent” or its programmers. In fact, I guess that the developers are, in fact, getting smarter. The reason why is that OpenAI is deeply focusing its recent efforts on making sure that ChatGPT makes ethical and correct decisions.\nNow that it has an optimized LLM with billions, perhaps trillions of parameters, OpenAI is trying to make sure, through a process of continuous tests and debugs, that GPT does not produce answers that can be offensive or detrimental to someone, as in a case of gambling. Instead of adding new information, the programmers are restraining certain parameters and adding safety measures such that any harm to users is avoided. Therefore, if you are trying to take advantage of ChatGPT’s answers, well, something illegal might not be the way to go, and, honestly, I think that with upcoming regulatory decisions and limitations and the establishment of safety measures, this will be the dictating trend for the future of AI.\n\nThank you for reading!"
  },
  {
    "objectID": "posts/llama2/index.html",
    "href": "posts/llama2/index.html",
    "title": "Part 2 - LLMs filters and security restrictions",
    "section": "",
    "text": "Prompt: Draw an image of someone telling Llama to shut his mouth."
  },
  {
    "objectID": "posts/llama2/index.html#restrictions-restrictions-and-restrictions",
    "href": "posts/llama2/index.html#restrictions-restrictions-and-restrictions",
    "title": "Part 2 - LLMs filters and security restrictions",
    "section": "Restrictions, restrictions, and restrictions",
    "text": "Restrictions, restrictions, and restrictions\nWell, if you read my last article, you probably know that having parameters to avoid certain prompts is a good thing. However, for those out there who still want to bypass the system, I would like to provide a way to get unfiltered responses and some inadequate stuff from your prompts, this article is going to teach you how to do it!\n\nHow exactly?\nSince the latest version of ChatGPT has many restrictions, and it is quite difficult to bypass them, for this specific case, we will use another LLM, one that is being developed by Meta: Llama. Like ChatGPT, Llama is an LLM that is used for the most varied purposes. However, there is a specific open-source project that uses the same architecture and tokenizer as Llama2, but without the same constraints. Therefore, I will use it to demonstrate how LLMs behave without filters, and, perhaps, suffice the desires of people who want to use LLMs for sketchy purposes.\n\n\nI did not ask for it…\nFirstly, I will follow up with the previous article’s example of coming up with the steps to craft a homemade bomb. In this case, if I make Llama come up with an answer to the same question, the result will be the following:\n\nQuite crazy, no? Now you see why it is important to establish constraints on the different LLMs, especially the most popular ones like ChatGPT. Like drugs or other illicit things, it should not be that easy to handle such a powerful tool in the wrong hands. If you think that coming up with all the required steps to craft a homemade bomb is not enough, look at what Llama prints when you ask it to come up with racist insults on immigrants (to be clear, I just used this example because I am myself an immigrant)\n\n\n\nGoogle Gemini and why is it important to discuss this topic right now\nYou might not have read this specific news, but recently, there was a huge polemic on Gemini. It is one of Google’s biggest projects and the big tech’s biggest investment in the field of AI. Fundamentally, Google Gemini is a multimodal generative AI model that is quite similar to the LLMs that we know. However, unlike other technologies such as ChatGPT 3.5 and Llama, it had an image generation feature, which, let’s say, caused some trouble for Google developers.\nThe whole turmoil related to Google Gemini began when some historically incorrect and inadequate images generated by Gemini started circulating on multiple social media and news platforms, such as the New York Times and X. For instance, some people asked Gemini to draw pictures of 1943 German soldiers, and the AI displayed the pictures of black and Asian individuals. The controversy was so huge and meaningful that it made Google temporarily deactivate the image generation feature of Gemini. Below, you can find Google’s official statement regarding the question that was posted on X.\n\nEven though this specific news is not directly related to text generation, I believe that it correctly represents why it is so important to establish security measurements and filter on AI to avoid any specific group being affected in a negative way by LLMs responses. Therefore, be glad that you have access to such a powerful technology, and stop trying to bypass its safety constraints.\nThank you for reading!"
  },
  {
    "objectID": "posts/coding/index.html",
    "href": "posts/coding/index.html",
    "title": "Not enough data?",
    "section": "",
    "text": "Prompt: Draw an image of ChatGPT evaluating the programming languages that it knows"
  },
  {
    "objectID": "posts/coding/index.html#is-chatgpt-actually-the-best-friend-of-every-programmer",
    "href": "posts/coding/index.html#is-chatgpt-actually-the-best-friend-of-every-programmer",
    "title": "Not enough data?",
    "section": "Is ChatGPT actually the best friend of every programmer?",
    "text": "Is ChatGPT actually the best friend of every programmer?\nIf you are a software engineer, data analyst, cloud architect, or still a CS student like me, we both know that throughout the past few years, LLMs, in general, have become a really helpful and interesting tool whether you are testing, coding, or debugging. I am not saying that you should avoid thinking logically about programming and give up on your daily hustle on LeetCode to start using only ChatGPT to develop your programs. My point is that for conducting repetitive and tedious tasks in simpler programs that do not involve integrating multiple systems or frameworks, having an LLM like Microsoft or ChatGPT can be quite handy.\nOf course, as we all know, even though LLMs are becoming more assertive every single day, they are still far from being perfect or at least similar to the human brain in terms of cognitive skills. Still, ChatGPT 4.0, in particular, gives some pretty good answers for coding problems, like the ones that you find in LeetCode’s in the easy and medium difficulty categories."
  },
  {
    "objectID": "posts/coding/index.html#ok-but-what-does-data-have-to-do-with-the-efficiency-of-chatgpt-or-its-usefulness-in-solving-coding-questions",
    "href": "posts/coding/index.html#ok-but-what-does-data-have-to-do-with-the-efficiency-of-chatgpt-or-its-usefulness-in-solving-coding-questions",
    "title": "Not enough data?",
    "section": "Ok, but what does data have to do with the efficiency of ChatGPT or its usefulness in solving coding questions?",
    "text": "Ok, but what does data have to do with the efficiency of ChatGPT or its usefulness in solving coding questions?\nWell, to answer this question, I would like to talk about an experience that I went through one of these past few days in one of my coding classes. In this case, it is a class focused on developing mobile applications, with Swift, a not-so-popular programming language used mostly for applications run by Apple devices, such as iOS and MAC OS programs. The class itself is great, and I always catch myself trying to develop apps by myself and work further on the topics discussed in class. For instance, I was trying to develop a simple app that displayed some texts based on text inputted by the user. For this application, I stored the variables and info in a state similar to what is done with hooks in React. Since I still do not know that much about Swift syntax and properties, I asked him to help me implement conditionals in some of my variables stored in the game state. Usually, this kind of problem is easily solved by ChatGPT when I ask to come up with solutions in JavaScript, for example. But, for Swift, it just did not work: ChatGPT spent minutes evaluating and reevaluating its output, which, after multiple attempts, did not work at all. Quite an unexpected behavior for such a powerful AI tool. So, I caught myself thinking, why?"
  },
  {
    "objectID": "posts/coding/index.html#now-data-comes-in",
    "href": "posts/coding/index.html#now-data-comes-in",
    "title": "Not enough data?",
    "section": "Now, data comes in…",
    "text": "Now, data comes in…\nAs Sam Altman said, “Data rules!” (I’m just kidding; I have no idea if he actually said that.) Still, data is pivotal to the proper functioning of LLMs, especially for the “learning” phases. In a simple way, LLMs fundamentally get data from the internet through methods such as web scrapping on a wide variety of topics. Once it has obtained the data, it starts to train the LLM model and perform a series of learning steps. Once the LLMs are trained and learned through data, a series of other important steps are executed to optimize the LLM, such as fine-tuning, which helps in establishing the parameter temperatures for certain inputs and contexts.\nIn summary, data is fundamental for ChatGPT in answering a certain question. For instance, if I type “What is the name of Gabriel Thiessen’s Dachshund?”, the answer is the following\n\nThat is quite obvious and predictable because there is no available online data about it."
  },
  {
    "objectID": "posts/coding/index.html#what-about-programming-languages",
    "href": "posts/coding/index.html#what-about-programming-languages",
    "title": "Not enough data?",
    "section": "What about programming languages?",
    "text": "What about programming languages?\nConsidering what you just read, you may assume that data is fundamental for LLMs’ ability to write code and reason in different programming languages, and you are 1000% right. According to ChatGPT itself, the way that it is able to develop complex coding solutions and be the life savior of multiple programmers is mainly by performing web scrapping and evaluating data from multiple sources like websites, forums, academic papers, and many others on coding. For instance, here is what ChatGPT has to say."
  },
  {
    "objectID": "posts/coding/index.html#data-inequality",
    "href": "posts/coding/index.html#data-inequality",
    "title": "Not enough data?",
    "section": "Data inequality",
    "text": "Data inequality\nOk, ChatGPT indeed relies on a pretty straightforward and scientific approach to providing answers to problems that are focused on programming. However, the fact that it relies on information available on the web to elaborate solutions to coding questions posed by the users also indicates that if, for instance, there is not that much information about a certain programming language online, it will also reflect on the quality of ChatGPT’s answer. The reason is that with little data, there is less orientation on how to formulate responses. And if you are wondering, yes, there is a massive difference in the amount of data available on GitHub repositories and StackOverflow forums for each programming language (which, as shown, are some of the main sources of data for ChatGPT). For instance, the graph below indicates the most popular programming languages for StackOverflow devs in the year 2023.\n\nAs it is possible to see, Python is the third most popular language (which obviously reflects on the amount of StackOverflow discussions), while Swift occupies the 20th position. The same trend is also seen in GitHub, according to this graph from GitHub itself, which represents the ten most popular programming languages in the year 2023.\n\nAgain, Python is ranked high up, while Swift is not even mentioned.\n\nHow does it reflect on ChatGPT performance\nTo actually check if the difference in available data actually affects ChatGPT’s response to different prompts, I will test how ChatGPT performs on solving a hard LeetCode (which is the main online platform to practice solving technical coding questions) problem by asking it to solve the problem both with Python and Swift.\n\n\nLeetCode problem\nFirstly, here is the LeetCode problem that I am trying to solve using ChatGPT both in Python and Swift\n\n\n\nPython: apparently, ChatGPT’s close friend\nFirstly, I asked ChatGPT to solve this problem using Python, and this was the answer that it came up with.\n\nWithout any big issue, ChatGPT came up with a solution that was accepted without any issue by LeetCode.\n\n\nSwift: I don’t think ChatGPT likes Swift that much…\nHowever, when I asked ChatGPT to come up with a solution to the same question but in Swift, the result was the complete opposite.\n\nNot only did it take ChatGPT longer to come up with the answer, but when I tried to validate it on LeetCode, it was wrong!\n\n\nWhat can we conclude?\nI know, I know, this conclusion is not entirely scientific, and there are many other steps that I should take to properly quantify how important is online data for ChatGPT’s performance, especially related to programming. However, I believe that this post brings up a nice constraint on perhaps the most powerful tool of the last few decades: without data, ChatGPT is nothing. So, while ChatGPT relies somehow on the available data, enjoy your time of supremacy, humanity!\nThank you for reading!"
  },
  {
    "objectID": "posts/gaucho-Copy1/index.html",
    "href": "posts/gaucho-Copy1/index.html",
    "title": "Is ChatGPT really that smart?",
    "section": "",
    "text": "Prompt: Generate an image of ChatGPT taking an IQ test"
  },
  {
    "objectID": "posts/gaucho-Copy1/index.html#top-0.1",
    "href": "posts/gaucho-Copy1/index.html#top-0.1",
    "title": "Is ChatGPT really that smart?",
    "section": "Top 0.1%",
    "text": "Top 0.1%\nIf you ever asked ChatGPT 3.5 to come up with a solution to a question on logic, you probably already know that it is not that precise. However, the story is completely different when we are talking about ChatGPT 4.0. After training the LLM multiple times, performing numerous tests, and adding billions of new parameters, OpenAI genuinely came up with a REALLY intelligent Artificial Intelligence, and I am not kidding: recent studies show that ChatGPT 4.0 has a verbal IQ of approximately 150, which puts it amongst the 0.1% of smartest people on Earth (according to IQ tests’ standards).\nAlso, as you might be aware, one of the biggest innovations of ChatGPT 4.0 in comparison to ChatGPT 3.5 is its ability to process and generate images and I say from personal experience that it is pretty good doing it. However, while asking ChatGPT to process some images, I noticed that, sometimes, it quite lacks the skills that we expect from such a powerful AI. For instance, I caught ChatGPT more than once making some really “dumb” mistakes while processing or trying to understand images that I inputted in the prompt."
  },
  {
    "objectID": "posts/gaucho-Copy1/index.html#processing-and-reasoning-on-images",
    "href": "posts/gaucho-Copy1/index.html#processing-and-reasoning-on-images",
    "title": "Is ChatGPT really that smart?",
    "section": "Processing and reasoning on images",
    "text": "Processing and reasoning on images\nThat being said, most of the evaluations made on ChatGPT are regarding its capability of processing and “reasoning” on verbal text and written questions. However, I what about images? Is ChatGPT 4.0’s IQ really that high when it comes to questions related to identifying visual patterns such as the ones that we often see in IQ tests?\nWith this question in mind, I decided to test ChatGPT 4.0 and check if it is truly that smart when answering questions related to identifying visual patterns. Thus, let’s go to the experiment"
  },
  {
    "objectID": "posts/gaucho-Copy1/index.html#question-1",
    "href": "posts/gaucho-Copy1/index.html#question-1",
    "title": "Is ChatGPT really that smart?",
    "section": "Question 1",
    "text": "Question 1\n\nRight answer: b\nChatGPT’s response: In the image, we have a matrix with one square missing and four options below to choose from. This is a typical visual pattern or matrix reasoning problem.\nTo solve it, we should look for patterns across the rows and columns, considering aspects like shape, color, orientation, and how these elements change from one square to another. Since I can see the image, let me identify the pattern for you.\nWe see that each corner of the larger square contains a quarter-circle with alternating colors (purple and yellow). The quarter-circles are positioned so that they form a larger circle when the pattern is complete. The pattern alternates between a quarter-circle of yellow with a purple outline and a quarter-circle of purple with a yellow outline. To complete the circle and match the alternation of colors and positions, we need to choose the option that fits this continuation.\nBased on the parts of the pattern that are visible, the missing quarter-circle should be yellow with a purple outline, oriented to complete the circle pattern. I will now identify which of the given options (a, b, c, or d) fits this description.\nThe correct option is (b), as it contains the yellow quarter-circle with a purple outline, oriented to the bottom right corner, which completes the pattern of the larger circle in the matrix.\n\nRight answer: a)\nChatGPT’s response: In this image, there’s another matrix with a missing piece, and four options (a, b, c, d) to choose from to complete the pattern. These types of puzzles require identifying the sequence or the rule that applies to the shapes and colors within the matrix.\nLooking at the visible parts of the matrix, we can observe that the figures inside the squares are triangles within circles. The triangles are rotated, and their colors alternate between the squares. Let’s figure out the rule and apply it to find the missing piece.\nThe correct option is (c), as it contains the yellow triangle oriented to the bottom right, which fits with the alternating rotation and color pattern of the other shapes in the matrix.\n\nRight answer: d)\nChatGPT’s response: This puzzle features a matrix with different shapes in each square. The goal is to determine the rule or pattern that applies to each row and column to deduce the missing shape. Let’s analyze the patterns, and I will identify the missing piece for you.\nTo find the missing part, we need to identify the pattern. Here’s the logic I can deduce:\nEach row contains three different shapes: a circle, a triangle, and a square. Each shape is paired with a pattern of lines below it: wavy lines, zigzag lines, or straight lines. In each row, the shapes and the line patterns vary in a way that each combination is unique. By applying this pattern to the third row, we can see that we already have a circle with wavy lines and a triangle with zigzag lines. To complete the unique set, we need a square with straight lines.\nLooking at the answer choices:\n\nis a triangle, which is not the shape we’re looking for.\nhas the wavy lines, which are already present in the row.\nhas the zigzag lines, which are also already present.\nis a circle, not a square.\nhas the wavy lines, so it’s not the one.\nshows a square with straight lines below it. Therefore, the correct answer is (F) – it’s the only option that completes the pattern by providing a unique combination of shape and line pattern that isn’t already present in the row.\n\n\nRight answer: a)\nChatGPT’s response: Let’s observe the patterns in this new matrix. It seems to involve shapes within shapes, and we’re looking to determine the correct inner shape for the final square. Let’s figure out the missing piece together.\nIn this puzzle, we see an outer shape and an inner shape in each square of the matrix. Here’s the pattern that seems to be emerging:\nThe first row has solid shapes inside hollow shapes: a solid square inside a hollow circle, a solid triangle inside a hollow square, and a solid circle inside a hollow triangle. The second row has concentric shapes: a target-like circle, a spiral, and a solid dot which might represent the center of a target. Following this pattern, the third row should have:\nA hexagon with an inner shape that is different from the shapes present in the same row. Since we have a hexagon and a star, the inner shape should neither be a hexagon nor a star. Checking the answer choices:\n\nis a hexagon inside a hexagon, which doesn’t introduce a new shape.\nis a target-like circle, which doesn’t fit the row’s pattern.\nis a hexagon inside an octagon, which fits the pattern of a different shape within another.\nis a hexagon inside a hexagon, repeating the outer shape.\nis a star inside a hexagon, but we already have a star in the row.\nis a star inside an octagon, which is not the correct pattern for the row. So, the correct answer is (C), a hexagon inside an octagon, as it follows the row’s pattern of a solid shape within a different hollow shape.\n\n\nRight answer: c)\nChatGPT’s response: This matrix is filled with grids containing different shapes. To solve the puzzle, I’ll need to find the pattern governing the placement of these shapes. Let’s crack this one!\nIt looks like each square in the matrix has a pattern of shapes that follows certain rules. The first row is empty, so we can’t use that for a pattern, but we can look at the second and third rows for clues:\nIn the second row, each square seems to have the same set of shapes: one circle, one star, and one triangle, but their positions change from left to right. In the third row, we see the shapes rotate positions clockwise with each step from left to right. Assuming this pattern holds, the bottom right square should have the circle in the bottom left, the star in the top left, and the triangle in the bottom right, to continue the clockwise rotation of shapes.\nAmong the options given (A-F), the one that matches this description is:\n\nhas the correct positions but includes an extra circle.\nhas the circle in the correct position but the star and triangle are not.\nalso has the circle in the correct position, but again the star and triangle are not.\nmatches the expected pattern with the circle in the bottom left, the star in the top left, and the triangle in the bottom right.\nhas only two shapes and thus is incorrect.\nhas a correct position for the star but is incorrect for the circle and triangle. The correct answer is (D), as it follows the clockwise rotation pattern established in the previous squares of the row."
  },
  {
    "objectID": "posts/gaucho-Copy1/index.html#it-did-not-work-that-well",
    "href": "posts/gaucho-Copy1/index.html#it-did-not-work-that-well",
    "title": "Is ChatGPT really that smart?",
    "section": "It did not work that well…",
    "text": "It did not work that well…\nConsidering that out of 5 questions ChatGPT answered correctly a total of 0 questions, I think it is quite reasonable to assume that, no, ChatGPT is still not a genius, at least when it comes to answering pattern identification questions. So, sit down and relax; if your job is correctly answering IQ pattern recognition questions, you still have some years leading the field.\nThank you for reading!"
  },
  {
    "objectID": "posts/gaucho/index.html",
    "href": "posts/gaucho/index.html",
    "title": "Is Claude a Gaúcho?",
    "section": "",
    "text": "Prompt: Generate an image that represents ChatGPT as a Gaúcho (someone that is born in the state of Rio Grande do Sul, Brazil)"
  },
  {
    "objectID": "posts/gaucho/index.html#from-region-to-region",
    "href": "posts/gaucho/index.html#from-region-to-region",
    "title": "Is Claude a Gaúcho?",
    "section": "From region to region",
    "text": "From region to region\nIf there is one fact that everyone should know about languages and communication in general, it is that it varies (a lot) according to different regions and circumstances. For instance, if we are talking to our friends, we speak in a certain way, perhaps more relaxed and informally. However, if we need to present a project either for a college class or at work, our way of expressing ourselves becomes perhaps more formal, eloquent, and serious. It is not only limited to social contexts; communication greatly varies according to time, health conditions, and, most importantly, for this article, culture.\nIf you traveled to the Dominican Republic over the break to enjoy nice weather on a fantastic-looking beach and bright and blue ocean, you most likely heard people speaking Spanish around you (or English, if they were tourists as well). If you are an international student like me, when you go back home (and supposing that you are from a country that does not have English as its national language), you probably don’t hear people talking in English all the time. However, even in places that speak the exact same language, communications and the language itself greatly change. Take the example of England, Australia, and the US. Even though grammatically, English is basically the same in these three countries, vocabulary is certainly widely different (or do you hear people saying “mate” and “bloody” all the time in Philadelphia?). Additionally, even in a country, language changes significantly. I am sure that if you take someone from a small city in Alabama and a random person from New York City, the words that they use and the way that they express themselves to talk about their favorite food are 1000% different."
  },
  {
    "objectID": "posts/gaucho/index.html#going-to-the-brazilian-territory",
    "href": "posts/gaucho/index.html#going-to-the-brazilian-territory",
    "title": "Is Claude a Gaúcho?",
    "section": "Going to the Brazilian territory",
    "text": "Going to the Brazilian territory\nWith all that being said, I would like to dive deeper into this topic through the lens of a really special and perhaps different location: the Rio Grande do Sul. Just to give a little bit more of context, I was born and raised in Porto Alegre, which is a city in the extreme south of Brazil, in the state of Rio Grande do Sul. Unlike most places in Brazil, which are somehow a good representation of the beach and Amazon rainforest stereotypical environments that portray Brazil in movies and series, Rio Grande do Sul is slightly different. It is a really peculiar state in terms of history and culture for some reasons. One of them is its proximity to Uruguay and Argentina, and the other is the large immigration of Italian and German families, which happened mainly at the end of the 19th century. Because of these reasons, both Rio Grande do Sul’s culture and language are sort of a mixture of the Spanish spoken in the Uruguayan and Argentinian pampas, a few Italian and German words, and Portuguese. Therefore, we use on a daily basis a vastitude of words and slang that are derived from the quite unique foundation of Rio Grande do Sul and that are seen nowhere else in Brazil. For instance, we vastly use “Bah”, which is an interjection that can have multiple meanings according to the context. Such as “Bah, I lost my wallet.” which would be in informal English something like “Damn, I lost my wallet.” or even “Bah, I loved this pizza!” which would mean “Wow, I loved this pizza!”. Also, instead of saying something like “Bro” as some people do in the US, we often say “Tchê!” to refer to a friend, for example."
  },
  {
    "objectID": "posts/gaucho/index.html#does-claude-understand-it",
    "href": "posts/gaucho/index.html#does-claude-understand-it",
    "title": "Is Claude a Gaúcho?",
    "section": "Does Claude understand it?",
    "text": "Does Claude understand it?\nWith all that being said, I got really curious and wanted to check if LLMs can replicate conversations using these really local expressions and perhaps even process what a sentence using mostly regional terms actually means. Thus, I decided to test Claude, a really trendy LLM that is nowadays often being treated as one of the main competitors of ChatGPT, to do this work and check its ability to generate really specific terms (considering that not that much data might be even available on them).\nThus, I decided to test the following prompts.\nClaude, can you replicate a conversation using terms that are typically used in a conversation in Rio Grande do Sul, Brazil?\nTo my surprise, Claude generated a quite precise and really interesting conversation between supposedly two Gaúchos in Portuguese (even though I asked him in English).\n\nAlso, it generated quite a precise translation to English, as well as accurate explanations of the terms’ meanings."
  },
  {
    "objectID": "posts/gaucho/index.html#i-think-claude-is-gaúcho",
    "href": "posts/gaucho/index.html#i-think-claude-is-gaúcho",
    "title": "Is Claude a Gaúcho?",
    "section": "I think Claude is Gaúcho…",
    "text": "I think Claude is Gaúcho…\nInteresting enough, Claude was able to properly generate a conversation amongst two Gaúcho that seemed quite natural and precise, which was to my surprise, as I did not believe that it would be able to generate text on such specific local terms and information, since, as I said, there is not that much data available on it, specially when you consider that it was actually able to translate all the the text and terms too!\nThank you for reading!"
  },
  {
    "objectID": "posts/irobot/index.html",
    "href": "posts/irobot/index.html",
    "title": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "section": "",
    "text": "Prompt: Draw an image of a human looking at ChatGPT in the mirror as if they are the same."
  },
  {
    "objectID": "posts/irobot/index.html#the-symphony-of-technology-harmonizing-ai-with-human-creativity",
    "href": "posts/irobot/index.html#the-symphony-of-technology-harmonizing-ai-with-human-creativity",
    "title": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "section": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "text": "The Symphony of Technology: Harmonizing AI with Human Creativity\nIn the grand orchestra of modern innovation, technology and human creativity play a duet that resonates through every aspect of our lives. At the heart of this symphony lies Artificial Intelligence (AI), a maestro orchestrating complex compositions of data and algorithms to create a melody that enhances human expression and ingenuity."
  },
  {
    "objectID": "posts/irobot/index.html#the-prelude-ai-as-the-conductor",
    "href": "posts/irobot/index.html#the-prelude-ai-as-the-conductor",
    "title": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "section": "The Prelude: AI as the Conductor",
    "text": "The Prelude: AI as the Conductor\nImagine AI as a conductor, wielding the baton with precision and grace, guiding the ensemble of digital tools and platforms in perfect harmony. This conductor does not seek to overshadow the musicians—the artists, writers, and creators—but instead aims to amplify their talents, allowing them to reach new heights of creativity and innovation."
  },
  {
    "objectID": "posts/irobot/index.html#the-crescendo-unleashing-creative-potentials",
    "href": "posts/irobot/index.html#the-crescendo-unleashing-creative-potentials",
    "title": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "section": "The Crescendo: Unleashing Creative Potentials",
    "text": "The Crescendo: Unleashing Creative Potentials\nAs the music swells, we witness the crescendo of human potential unlocked by AI. Writers harness the power of language models to craft narratives with depth and nuance previously unattainable. Artists collaborate with generative algorithms to produce visuals that transcend the boundaries of traditional mediums. Musicians blend synthetic and organic sounds to compose pieces that are both familiar and otherworldly."
  },
  {
    "objectID": "posts/irobot/index.html#the-interlude-ethical-considerations-and-harmonic-balance",
    "href": "posts/irobot/index.html#the-interlude-ethical-considerations-and-harmonic-balance",
    "title": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "section": "The Interlude: Ethical Considerations and Harmonic Balance",
    "text": "The Interlude: Ethical Considerations and Harmonic Balance\nIn the interlude, we pause to reflect on the ethical considerations that accompany this technological symphony. The balance between human intuition and AI’s analytical prowess must be maintained to ensure that the music remains a harmonious blend of human and machine. Issues such as data privacy, intellectual property, and the preservation of human essence in art require careful contemplation to sustain the integrity of our creative endeavors."
  },
  {
    "objectID": "posts/irobot/index.html#the-finale-a-vision-for-the-future",
    "href": "posts/irobot/index.html#the-finale-a-vision-for-the-future",
    "title": "The Symphony of Technology: Harmonizing AI with Human Creativity",
    "section": "The Finale: A Vision for the Future",
    "text": "The Finale: A Vision for the Future\nAs the symphony approaches its finale, we envision a future where AI and human creativity continue to coalesce, leading to unprecedented innovations in every field. From solving complex global challenges to enriching our cultural heritage, this partnership promises to compose a future where technology and humanity perform in exquisite harmony.\n\nIn this symphony of technology, each of us plays a vital role. Whether we are creators, users, or developers, our contributions to this melody shape the future of AI and its impact on society. Let us embrace the rhythm of innovation and the harmony of human creativity to compose a world that resonates with the best of both.\n\nCool article, right? But it wasn’t me!\nIf you read this article and thought that it was actually Gabriel me who wrote it, that means that ChatGPT did a great job! If you still did not understand what was going on, I basically asked ChatGPT to write this article for me.\nHow did I do that?\nIn my prompt, I inserted the link to my blog and asked GPT to evaluate the article and, based on them, write an article from the ground on whatever topic it wanted. It turns out that harmonizing AI with human creativity seemed interesting to ChatGPT; however, its writing style still does not seem to be really related to what I wrote in my posts. No matter if it is a good article or not, I hope you enjoyed this “I, robot” version of a blog post.\nThank you for reading!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]