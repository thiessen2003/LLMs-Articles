{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"1 + 1 = 2 ... perhaps not for Microsoft Copilot\"\n",
    "description: \"A brief analysis of one of Microsoft Copilot weaknesses\"\n",
    "author: \"Gabriel\"\n",
    "date: \"2/10/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - Copilot\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47332d49-fa83-4376-8adc-4f924ec94c79",
   "metadata": {},
   "source": [
    "## A simple counting problem \n",
    "\n",
    "* For most people, counting numbers is a simple operation composed of basically adding numbers. From an early age, most of us know how to compute 1 + 1, 2 + 2, and 2 - 1. It is an intuitive operation that is ubiquitous in our daily lives. As LLMs are basically developed to generate responses that are most likely human ones, one would infer that LLMs do not have a problem in computing the total price of multiple objects, calculating means and medians, and counting the number of letters in a single word... However, this last one might not be so easy for them to figure out. To better understand what I am saying, let's go through a sample question\n",
    "* \n",
    "> Count the number that each letter appears in the word college."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7e97a-f92e-411d-8c62-1608d7820af7",
   "metadata": {},
   "source": [
    "You will probably answer something like **c = 1, o = 1, l = 2, e = 2, g = 1**...\n",
    "\n",
    "And that's it! There is no interpretation, no magical formula, no advanced counting theorem. Just pure and simple math. However, how do we really perform this operation? \n",
    "\n",
    "### How do we do it?\n",
    "\n",
    "Some people might deliberate a bit on these simple additions, especially people who might instantly respond to the questions. No matter if it is our automatic or analytical brain system (shoutout to Daniel Kahneman) that is performing the operation, one thing is for sure: it is a simple counting operation. \n",
    "\n",
    "We basically identify different characters visually based on previous knowledge of the alphabet and its characters and perform logical steps composed of adding numbers to check how many times the characters with the same visual representation are represented in this specific range of letters. This ability to perform simple operations (which are not too simple for a machine) comes from our brain's impressive capacity for interpreting, storing, and using visual data for other means. It is as simple as that: you look, interpret, and do whatever you want with this information without any additional step to evaluate such values. However, that is not how LLMs work. \n",
    "\n",
    "To perform any type of operation, LLMs rely on a process called tokenization. Tokenization is one of the fundamental steps in data analysis for LLMs in which they process, usually words, as a set of integers. For instance, while we read \"dog\" as just \"dog,\" a machine interprets dogs as 001. This step is pivotal for generative AI, as it allows the machine to make associations of what words most often appear after the dog in a sentence and, thus, allows it to come up with a plausible answer. \n",
    "\n",
    "\n",
    "**But letters are a whole different story...**\n",
    "You might be wondering, what if we want to analyze letters in a word? This tokenization process is then applied to each individual character in the designated word, which turns out to be troublesome for some specific LLMs. In the case of Copilot, no matter if it is a common word in terms of recurrence or an unusual word, it has difficulties in tokenizing it. Check it out below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4f8ce-0eb8-47b7-ab32-026a9efd5f34",
   "metadata": {},
   "source": [
    "### How does Copilot respond to the prompt?\n",
    "\n",
    "**GPT3.5 Turbo**\n",
    "\n",
    "<img src=\"anthropology.png\" width=\"50%\"/>\n",
    "\n",
    "* As you can see, it has a lot of difficulties processing the word **anthropology**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f185c75-dea4-4e1c-983e-978feba55956",
   "metadata": {},
   "source": [
    "**What about other words**\n",
    "\n",
    "<img src=\"college.png\" width=\"50%\"/>\n",
    "\n",
    "* This time, though, Copilot successfully counted the number of letters in the word **college**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27796f57-25f2-4817-8072-f0e122c78580",
   "metadata": {},
   "source": [
    "**Is is the same thing for ChatGPT 4?**\n",
    "\n",
    "<img src=\"gpt.png\" width=\"50%\"/>\n",
    "\n",
    "* Unlike what you may be thinking, not actually. Supposedly, Copilot uses Open AI's GPT 4, too. However, when we insert the exact same prompt on ChatGPT 4, it **answers correctly**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c140df-e2bd-4191-81b4-fd87ed4492ea",
   "metadata": {},
   "source": [
    "**What can we conclude with this experiment?**\n",
    "\n",
    "I would say that the results obtained can show us two important things: LLMs are still, in general, not good at processing individual words, and ChatGPT 4 and Copilot are perhaps not as similar as we thought. \n",
    "\n",
    "Regarding the first assertion, doing this experience makes it really easy to visualize the limitations of performing tokenization in comparison to the way that the human brain interprets words and counting. Probably, for more unusual words, like **anthropology**, Copilot simply attributes the same tokens to different letters or computes syllables as single words. Meanwhile, for more usual words in the English language, like **college**, its word tokenization process is more optimized and thus does not generate any problem in terms of interpretation and computation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c17e5-c44b-4f26-85c5-808a90d57623",
   "metadata": {},
   "source": [
    "**WHAT ABOUT ChatGPT 4?**\n",
    "\n",
    "Well, that is content for other articles, but at least in theory, Copilot should behave similarly to ChatGPT 4. Perhaps this indicates that, in fact, ChatGPT 4 and Copilot are not as similar as Microsoft proposed...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb0821-1a4a-4b19-b8bf-f4004f1e4b9f",
   "metadata": {},
   "source": [
    "**Thank you for reading!**"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3.11 (COMM4190)",
   "language": "python",
   "name": "comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
