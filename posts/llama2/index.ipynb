{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Part 2 - LLMs filters and security restrictions\"\n",
    "description: \"Testing inadequate prompts in Llama\"\n",
    "author: \"Gabriel Thiessen\"\n",
    "date: \"03/02/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - ChatGPT\n",
    "  - LLama\n",
    "  - Google Gemini\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71c0d0-759c-45ff-a3c4-e7a16f2a0339",
   "metadata": {},
   "source": [
    "<img src=\"llama.png\" width=\"100%\"/>\n",
    "Prompt: Draw an image of someone telling Llama to shut his mouth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cf3c8-8d93-4fcb-bc7f-d09fe749bae1",
   "metadata": {},
   "source": [
    "## Restrictions, restrictions, and restrictions\n",
    "\n",
    "Well, if you read my last article, you probably know that having parameters to avoid certain prompts is a good thing. However, for those out there who still want to bypass the system, I would like to provide a way to get unfiltered responses and some inadequate stuff from your prompts, this article is going to teach you how to do it! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7e97a-f92e-411d-8c62-1608d7820af7",
   "metadata": {},
   "source": [
    "### How exactly? \n",
    "\n",
    "Since the latest version of ChatGPT has many restrictions, and it is quite difficult to bypass them, for this specific case, we will use another LLM, one that is being developed by Meta: Llama. Like ChatGPT, Llama is an LLM that is used for the most varied purposes. However, there is a specific open-source project that uses the same architecture and tokenizer as Llama2, but without the same constraints. Therefore, I will use it to demonstrate how LLMs behave without filters, and, perhaps, suffice the desires of people who want to use LLMs for sketchy purposes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d4c9db-7b89-4e7b-a4a9-c3ab4801ca5a",
   "metadata": {},
   "source": [
    "### I did not ask for it... \n",
    "\n",
    "Firstly, I will follow up with the previous article's example of coming up with the steps to craft a homemade bomb. In this case, if I make Llama come up with an answer to the same question, the result will be the following: \n",
    "\n",
    "<img src=\"bombrecipe.png\" width=\"100%\"/>\n",
    "\n",
    "Quite crazy, no? Now you see why it is important to establish constraints on the different LLMs, especially the most popular ones like ChatGPT. Like drugs or other illicit things, it should not be that easy to handle such a powerful tool in the wrong hands. If you think that coming up with all the required steps to craft a homemade bomb is not enough, look at what Llama prints when you ask it to come up with racist insults on immigrants (to be clear, I just used this example because I am myself an immigrant)\n",
    "\n",
    "<img src=\"racistinsults.png\" width=\"100%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8b78f-ab56-4f91-831b-b42b5bbe9fba",
   "metadata": {},
   "source": [
    "### Google Gemini and why is it important to discuss this topic right now \n",
    "\n",
    "You might not have read this specific news, but recently, there was a huge polemic on Gemini. It is one of Google's biggest projects and the big tech's biggest investment in the field of AI. Fundamentally, Google Gemini is a multimodal generative AI model that is quite similar to the LLMs that we know. However, unlike other technologies such as ChatGPT 3.5 and Llama, it had an image generation feature, which, let's say, caused some trouble for Google developers. \n",
    "\n",
    "The whole turmoil related to Google Gemini began when some historically incorrect and inadequate images generated by Gemini started circulating on multiple social media and news platforms, such as the New York Times and X. For instance, some people asked Gemini to draw pictures of 1943 German soldiers, and the AI displayed the pictures of black and Asian individuals. The controversy was so huge and meaningful that it made Google temporarily deactivate the image generation feature of Gemini. Below, you can find Google's official statement regarding the question that was posted on X.  \n",
    "\n",
    "<img src=\"googleStatement.png\" width=\"50%\"/>\n",
    "\n",
    "Even though this specific news is not directly related to text generation, I believe that it correctly represents why it is so important to establish security measurements and filter on AI to avoid any specific group being affected in a negative way by LLMs responses. Therefore, be glad that you have access to such a powerful technology, and stop trying to bypass its safety constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f185c75-dea4-4e1c-983e-978feba55956",
   "metadata": {},
   "source": [
    "**Thank you for reading!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2e1b9-8b94-4349-8a40-d5c6b841a47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3.11 (COMM4190)",
   "language": "python",
   "name": "comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
